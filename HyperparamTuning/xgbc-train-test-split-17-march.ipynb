{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7708535,"sourceType":"datasetVersion","datasetId":4500787}],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nall_feature = pd.read_csv('/kaggle/input/abc-feature-labels/all_features(with jerk).csv')\nall_label = pd.read_csv('/kaggle/input/abc-feature-labels/all_labels(with jerk).csv')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-17T06:30:23.130890Z","iopub.execute_input":"2024-03-17T06:30:23.131304Z","iopub.status.idle":"2024-03-17T06:30:25.055533Z","shell.execute_reply.started":"2024-03-17T06:30:23.131276Z","shell.execute_reply":"2024-03-17T06:30:25.053858Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#all_feature = all_feature.to_numpy()\n#print(all_feature.shape)\n#print(all_label.shape)\n#all_label = all_label.to_numpy()\n#all_label = all_label.T.flatten()\n#print(all_label.shape)\n\nfrom xgboost import XGBClassifier","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:30.791531Z","iopub.execute_input":"2024-03-17T06:29:30.792045Z","iopub.status.idle":"2024-03-17T06:29:32.611450Z","shell.execute_reply.started":"2024-03-17T06:29:30.791951Z","shell.execute_reply":"2024-03-17T06:29:32.610192Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import RandomizedSearchCV, train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import MinMaxScaler","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:36.777913Z","iopub.execute_input":"2024-03-17T06:29:36.778343Z","iopub.status.idle":"2024-03-17T06:29:36.786652Z","shell.execute_reply.started":"2024-03-17T06:29:36.778314Z","shell.execute_reply":"2024-03-17T06:29:36.785559Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Define XGBC\nmodel = XGBClassifier(random_state=42)\n\n# Create Pipeline\nsteps = list()\nsteps.append(('scaler', MinMaxScaler()))\nsteps.append(('classifier', model))\npipeline = Pipeline(steps=steps)\n\n# Define Parameters\n\nparams= {\n    'classifier__learning_rate': [0.3, 0.1, 0.01, 0.001],\n    'classifier__max_depth':[1, 3, 5, 10, 15, 20],\n    'classifier__min_child_weight': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n    'classifier__subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n    'classifier__colsample_bytree': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n    'classifier__n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000]   \n}","metadata":{"execution":{"iopub.status.busy":"2024-02-27T17:28:19.890348Z","iopub.execute_input":"2024-02-27T17:28:19.891091Z","iopub.status.idle":"2024-02-27T17:28:19.903013Z","shell.execute_reply.started":"2024-02-27T17:28:19.891054Z","shell.execute_reply":"2024-02-27T17:28:19.901985Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#Random search for ideal n_estimators\nprint(f'Searching for the best value of parameter for {model}...')\nclassifier = RandomizedSearchCV(pipeline, params, cv=5, n_jobs=-1, scoring='f1_macro').fit(all_feature, all_label)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T17:28:19.904505Z","iopub.execute_input":"2024-02-27T17:28:19.905641Z","iopub.status.idle":"2024-02-27T20:05:49.296353Z","shell.execute_reply.started":"2024-02-27T17:28:19.905602Z","shell.execute_reply":"2024-02-27T20:05:49.294335Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Searching for the best value of parameter for XGBClassifier(base_score=None, booster=None, callbacks=None,\n              colsample_bylevel=None, colsample_bynode=None,\n              colsample_bytree=None, device=None, early_stopping_rounds=None,\n              enable_categorical=False, eval_metric=None, feature_types=None,\n              gamma=None, grow_policy=None, importance_type=None,\n              interaction_constraints=None, learning_rate=None, max_bin=None,\n              max_cat_threshold=None, max_cat_to_onehot=None,\n              max_delta_step=None, max_depth=None, max_leaves=None,\n              min_child_weight=None, missing=nan, monotone_constraints=None,\n              multi_strategy=None, n_estimators=None, n_jobs=None,\n              num_parallel_tree=None, random_state=42, ...)...\n","output_type":"stream"}]},{"cell_type":"code","source":"print(classifier.cv_results_)\nprint(classifier.best_params_)\nprint(classifier.best_score_)","metadata":{"execution":{"iopub.status.busy":"2024-02-27T20:05:49.301203Z","iopub.execute_input":"2024-02-27T20:05:49.301550Z","iopub.status.idle":"2024-02-27T20:05:49.313142Z","shell.execute_reply.started":"2024-02-27T20:05:49.301521Z","shell.execute_reply":"2024-02-27T20:05:49.311916Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"{'mean_fit_time': array([ 335.01836624,  352.71119857,  842.03974824,  264.60356288,\n        763.94471469,  361.27046428,  658.87858138,  274.59868097,\n        637.13084025, 2012.99875693]), 'std_fit_time': array([  5.43495234,  10.85406646,  10.31074642,   4.15882746,\n         8.91261015,   4.68474744,   4.92440637,   2.29613875,\n        10.97854542, 251.33286691]), 'mean_score_time': array([0.19079752, 0.18921905, 0.46103029, 0.16441598, 0.40505953,\n       0.15457807, 0.37902775, 0.12577448, 0.32993107, 1.25540094]), 'std_score_time': array([0.02539847, 0.00650911, 0.04773975, 0.00254092, 0.0052013 ,\n       0.00367312, 0.05661182, 0.00070699, 0.00324193, 0.15271334]), 'param_classifier__subsample': masked_array(data=[0.6, 1.0, 0.5, 0.8, 0.5, 0.9, 0.9, 0.5, 0.7, 1.0],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'param_classifier__n_estimators': masked_array(data=[500, 100, 900, 200, 800, 900, 700, 700, 900, 800],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'param_classifier__min_child_weight': masked_array(data=[5, 5, 2, 1, 2, 7, 10, 5, 10, 5],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'param_classifier__max_depth': masked_array(data=[3, 15, 5, 5, 5, 1, 10, 1, 3, 15],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'param_classifier__learning_rate': masked_array(data=[0.3, 0.01, 0.1, 0.1, 0.1, 0.3, 0.1, 0.01, 0.1, 0.001],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'param_classifier__colsample_bytree': masked_array(data=[0.5, 0.8, 0.7, 0.6, 0.7, 0.6, 0.8, 0.5, 0.8, 0.5],\n             mask=[False, False, False, False, False, False, False, False,\n                   False, False],\n       fill_value='?',\n            dtype=object), 'params': [{'classifier__subsample': 0.6, 'classifier__n_estimators': 500, 'classifier__min_child_weight': 5, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.3, 'classifier__colsample_bytree': 0.5}, {'classifier__subsample': 1.0, 'classifier__n_estimators': 100, 'classifier__min_child_weight': 5, 'classifier__max_depth': 15, 'classifier__learning_rate': 0.01, 'classifier__colsample_bytree': 0.8}, {'classifier__subsample': 0.5, 'classifier__n_estimators': 900, 'classifier__min_child_weight': 2, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.7}, {'classifier__subsample': 0.8, 'classifier__n_estimators': 200, 'classifier__min_child_weight': 1, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.6}, {'classifier__subsample': 0.5, 'classifier__n_estimators': 800, 'classifier__min_child_weight': 2, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.7}, {'classifier__subsample': 0.9, 'classifier__n_estimators': 900, 'classifier__min_child_weight': 7, 'classifier__max_depth': 1, 'classifier__learning_rate': 0.3, 'classifier__colsample_bytree': 0.6}, {'classifier__subsample': 0.9, 'classifier__n_estimators': 700, 'classifier__min_child_weight': 10, 'classifier__max_depth': 10, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.8}, {'classifier__subsample': 0.5, 'classifier__n_estimators': 700, 'classifier__min_child_weight': 5, 'classifier__max_depth': 1, 'classifier__learning_rate': 0.01, 'classifier__colsample_bytree': 0.5}, {'classifier__subsample': 0.7, 'classifier__n_estimators': 900, 'classifier__min_child_weight': 10, 'classifier__max_depth': 3, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.8}, {'classifier__subsample': 1.0, 'classifier__n_estimators': 800, 'classifier__min_child_weight': 5, 'classifier__max_depth': 15, 'classifier__learning_rate': 0.001, 'classifier__colsample_bytree': 0.5}], 'split0_test_score': array([0.47507218, 0.42656897, 0.47968528, 0.45693166, 0.47620891,\n       0.45696314, 0.47254002, 0.31477668, 0.49085731, 0.40325598]), 'split1_test_score': array([0.56328992, 0.50713087, 0.57348921, 0.56161023, 0.57246893,\n       0.5365441 , 0.56121395, 0.36697294, 0.56290878, 0.50602771]), 'split2_test_score': array([0.52335848, 0.4695021 , 0.56300185, 0.54962216, 0.56325403,\n       0.5293513 , 0.50781226, 0.34126046, 0.54411077, 0.45898445]), 'split3_test_score': array([0.60536735, 0.55315459, 0.59715131, 0.56119509, 0.59597234,\n       0.59619513, 0.61203147, 0.38543433, 0.59854651, 0.53819604]), 'split4_test_score': array([0.60247013, 0.51358815, 0.6080415 , 0.58624977, 0.60265141,\n       0.54910171, 0.59102943, 0.35862797, 0.59272158, 0.53332149]), 'mean_test_score': array([0.55391161, 0.49398894, 0.56427383, 0.54312178, 0.56211112,\n       0.53363108, 0.54892543, 0.35341448, 0.55782899, 0.48795713]), 'std_test_score': array([0.04948277, 0.04290098, 0.04525108, 0.0447202 , 0.04533846,\n       0.0448517 , 0.05182885, 0.02398701, 0.03892199, 0.05083723]), 'rank_test_score': array([ 4,  8,  1,  6,  2,  7,  5, 10,  3,  9], dtype=int32)}\n{'classifier__subsample': 0.5, 'classifier__n_estimators': 900, 'classifier__min_child_weight': 2, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.7}\n0.5642738288440016\n","output_type":"stream"}]},{"cell_type":"code","source":"#{'classifier__subsample': 0.5, 'classifier__n_estimators': 900, 'classifier__min_child_weight': 2, 'classifier__max_depth': 5, 'classifier__learning_rate': 0.1, 'classifier__colsample_bytree': 0.7}\n#0.5642738288440016\n#model_final = XGBClassifier(C=10, class_weight=None,solver='saga', max_iter=500, random_state=42)\nmodel_final = XGBClassifier(subsample= 0.5, n_estimators= 900, min_child_weight=2,\\\n                            max_depth = 5, learning_rate= 0.1, colsample_bytree = 0.7,random_state=42)","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:29:47.818906Z","iopub.execute_input":"2024-03-17T06:29:47.819315Z","iopub.status.idle":"2024-03-17T06:29:47.824918Z","shell.execute_reply.started":"2024-03-17T06:29:47.819287Z","shell.execute_reply":"2024-03-17T06:29:47.823596Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"test_sizes=[0.09, 0.1 , 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19,\n       0.2 , 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3 ,\n       0.31, 0.32, 0.33, 0.34, 0.35]\nfor test_size_curr in test_sizes:\n    # Split train-test data\n    f_train,f_test,l_train,l_test = train_test_split(all_feature, all_label, test_size = test_size_curr,\\\n                                                 random_state=42, shuffle = True)\n\n    # Scale data\n    scaler = MinMaxScaler()\n    scaler.fit(f_train)\n    f_train = scaler.transform(f_train)\n    f_test = scaler.transform(f_test)\n\n\n    # Fit + Train data\n    model_final.fit(f_train,l_train)\n    prediction = model_final.predict(f_test)\n\n    print(f'Train/Test split={(1-test_size_curr)*100}/{test_size_curr*100}')\n    # Evaluate\n    print(classification_report(l_test,prediction))","metadata":{"execution":{"iopub.status.busy":"2024-03-17T06:32:04.664331Z","iopub.execute_input":"2024-03-17T06:32:04.664931Z","iopub.status.idle":"2024-03-17T09:02:09.451640Z","shell.execute_reply.started":"2024-03-17T06:32:04.664885Z","shell.execute_reply":"2024-03-17T09:02:09.450485Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Train/Test split=91.0/9.0\n              precision    recall  f1-score   support\n\n           0       0.87      0.95      0.91       261\n           1       0.67      0.67      0.67        12\n           2       0.96      1.00      0.98        77\n           3       0.85      0.42      0.56        26\n           4       0.89      0.82      0.85       147\n           5       0.82      0.61      0.70        23\n           6       0.82      0.88      0.85        26\n           7       0.95      0.96      0.96       247\n           8       0.96      0.93      0.95        56\n\n    accuracy                           0.91       875\n   macro avg       0.87      0.81      0.83       875\nweighted avg       0.90      0.91      0.90       875\n\nTrain/Test split=90.0/10.0\n              precision    recall  f1-score   support\n\n           0       0.89      0.96      0.92       295\n           1       0.57      0.62      0.59        13\n           2       0.98      0.99      0.98        86\n           3       0.87      0.46      0.60        28\n           4       0.90      0.83      0.86       154\n           5       0.94      0.64      0.76        25\n           6       0.89      0.80      0.84        30\n           7       0.93      0.97      0.95       280\n           8       0.95      0.93      0.94        61\n\n    accuracy                           0.91       972\n   macro avg       0.88      0.80      0.83       972\nweighted avg       0.91      0.91      0.91       972\n\nTrain/Test split=89.0/11.0\n              precision    recall  f1-score   support\n\n           0       0.88      0.96      0.92       322\n           1       0.71      0.62      0.67        16\n           2       0.96      0.98      0.97        95\n           3       0.81      0.46      0.59        28\n           4       0.87      0.82      0.84       170\n           5       0.89      0.65      0.76        26\n           6       0.88      0.88      0.88        33\n           7       0.94      0.96      0.95       310\n           8       0.97      0.91      0.94        69\n\n    accuracy                           0.91      1069\n   macro avg       0.88      0.81      0.83      1069\nweighted avg       0.91      0.91      0.90      1069\n\nTrain/Test split=88.0/12.0\n              precision    recall  f1-score   support\n\n           0       0.87      0.97      0.92       354\n           1       0.73      0.61      0.67        18\n           2       0.98      0.95      0.97       106\n           3       0.76      0.59      0.67        32\n           4       0.90      0.83      0.86       191\n           5       0.94      0.62      0.74        26\n           6       0.85      0.85      0.85        34\n           7       0.95      0.95      0.95       330\n           8       0.94      0.91      0.93        75\n\n    accuracy                           0.91      1166\n   macro avg       0.88      0.81      0.84      1166\nweighted avg       0.91      0.91      0.91      1166\n\nTrain/Test split=87.0/13.0\n              precision    recall  f1-score   support\n\n           0       0.89      0.96      0.92       380\n           1       0.70      0.70      0.70        20\n           2       0.97      0.95      0.96       117\n           3       0.77      0.57      0.66        35\n           4       0.89      0.84      0.87       208\n           5       0.91      0.65      0.75        31\n           6       0.83      0.81      0.82        36\n           7       0.94      0.96      0.95       357\n           8       0.96      0.91      0.94        80\n\n    accuracy                           0.91      1264\n   macro avg       0.87      0.82      0.84      1264\nweighted avg       0.91      0.91      0.91      1264\n\nTrain/Test split=86.0/14.000000000000002\n              precision    recall  f1-score   support\n\n           0       0.88      0.95      0.91       414\n           1       0.74      0.71      0.72        24\n           2       0.98      0.97      0.97       125\n           3       0.73      0.53      0.61        36\n           4       0.87      0.83      0.85       221\n           5       0.91      0.64      0.75        33\n           6       0.83      0.81      0.82        36\n           7       0.94      0.96      0.95       383\n           8       0.95      0.91      0.93        89\n\n    accuracy                           0.90      1361\n   macro avg       0.87      0.81      0.84      1361\nweighted avg       0.90      0.90      0.90      1361\n\nTrain/Test split=85.0/15.0\n              precision    recall  f1-score   support\n\n           0       0.86      0.95      0.90       439\n           1       0.74      0.68      0.71        25\n           2       0.98      0.96      0.97       132\n           3       0.69      0.58      0.63        38\n           4       0.88      0.79      0.83       239\n           5       0.77      0.64      0.70        36\n           6       0.86      0.79      0.83        39\n           7       0.94      0.95      0.95       414\n           8       0.96      0.90      0.92        96\n\n    accuracy                           0.90      1458\n   macro avg       0.85      0.80      0.83      1458\nweighted avg       0.89      0.90      0.89      1458\n\nTrain/Test split=84.0/16.0\n              precision    recall  f1-score   support\n\n           0       0.85      0.96      0.90       468\n           1       0.75      0.72      0.74        29\n           2       0.97      0.94      0.95       140\n           3       0.72      0.56      0.63        41\n           4       0.90      0.79      0.84       256\n           5       0.84      0.65      0.73        40\n           6       0.82      0.80      0.81        40\n           7       0.93      0.95      0.94       440\n           8       0.98      0.86      0.92       101\n\n    accuracy                           0.89      1555\n   macro avg       0.86      0.80      0.83      1555\nweighted avg       0.90      0.89      0.89      1555\n\nTrain/Test split=83.0/17.0\n              precision    recall  f1-score   support\n\n           0       0.86      0.96      0.90       501\n           1       0.73      0.66      0.69        29\n           2       0.99      0.93      0.96       145\n           3       0.74      0.60      0.67        43\n           4       0.88      0.79      0.83       269\n           5       0.93      0.63      0.75        41\n           6       0.82      0.84      0.83        43\n           7       0.93      0.96      0.95       473\n           8       0.98      0.88      0.93       108\n\n    accuracy                           0.90      1652\n   macro avg       0.87      0.80      0.83      1652\nweighted avg       0.90      0.90      0.89      1652\n\nTrain/Test split=82.0/18.0\n              precision    recall  f1-score   support\n\n           0       0.87      0.94      0.90       535\n           1       0.70      0.77      0.73        30\n           2       0.97      0.93      0.95       152\n           3       0.86      0.56      0.68        45\n           4       0.87      0.81      0.84       289\n           5       0.85      0.69      0.76        42\n           6       0.83      0.84      0.84        45\n           7       0.93      0.96      0.94       498\n           8       0.94      0.88      0.91       113\n\n    accuracy                           0.90      1749\n   macro avg       0.87      0.82      0.84      1749\nweighted avg       0.90      0.90      0.89      1749\n\nTrain/Test split=81.0/19.0\n              precision    recall  f1-score   support\n\n           0       0.87      0.94      0.90       557\n           1       0.73      0.67      0.70        33\n           2       0.97      0.93      0.95       162\n           3       0.76      0.55      0.64        47\n           4       0.87      0.83      0.85       300\n           5       0.85      0.62      0.72        45\n           6       0.78      0.78      0.78        49\n           7       0.93      0.96      0.94       532\n           8       0.96      0.88      0.92       122\n\n    accuracy                           0.89      1847\n   macro avg       0.86      0.79      0.82      1847\nweighted avg       0.89      0.89      0.89      1847\n\nTrain/Test split=80.0/20.0\n              precision    recall  f1-score   support\n\n           0       0.86      0.94      0.90       589\n           1       0.65      0.65      0.65        34\n           2       0.98      0.92      0.95       171\n           3       0.77      0.55      0.64        49\n           4       0.87      0.79      0.83       318\n           5       0.93      0.70      0.80        53\n           6       0.78      0.77      0.78        52\n           7       0.92      0.96      0.94       551\n           8       0.95      0.88      0.91       127\n\n    accuracy                           0.89      1944\n   macro avg       0.86      0.80      0.82      1944\nweighted avg       0.89      0.89      0.89      1944\n\nTrain/Test split=79.0/21.0\n              precision    recall  f1-score   support\n\n           0       0.86      0.93      0.89       617\n           1       0.73      0.61      0.67        36\n           2       0.95      0.92      0.94       182\n           3       0.83      0.62      0.71        55\n           4       0.87      0.80      0.83       335\n           5       0.89      0.71      0.79        55\n           6       0.82      0.76      0.79        54\n           7       0.92      0.96      0.94       575\n           8       0.97      0.89      0.92       132\n\n    accuracy                           0.89      2041\n   macro avg       0.87      0.80      0.83      2041\nweighted avg       0.89      0.89      0.89      2041\n\nTrain/Test split=78.0/22.0\n              precision    recall  f1-score   support\n\n           0       0.86      0.93      0.89       652\n           1       0.71      0.58      0.64        38\n           2       0.96      0.92      0.94       191\n           3       0.78      0.62      0.69        56\n           4       0.86      0.79      0.82       354\n           5       0.85      0.62      0.72        56\n           6       0.80      0.78      0.79        55\n           7       0.92      0.96      0.94       600\n           8       0.95      0.90      0.92       136\n\n    accuracy                           0.89      2138\n   macro avg       0.85      0.79      0.82      2138\nweighted avg       0.88      0.89      0.88      2138\n\nTrain/Test split=77.0/23.0\n              precision    recall  f1-score   support\n\n           0       0.86      0.93      0.89       679\n           1       0.60      0.55      0.58        38\n           2       0.95      0.91      0.93       199\n           3       0.79      0.54      0.65        57\n           4       0.86      0.80      0.83       372\n           5       0.88      0.63      0.73        59\n           6       0.79      0.71      0.75        58\n           7       0.92      0.96      0.94       632\n           8       0.95      0.89      0.92       141\n\n    accuracy                           0.88      2235\n   macro avg       0.84      0.77      0.80      2235\nweighted avg       0.88      0.88      0.88      2235\n\nTrain/Test split=76.0/24.0\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       707\n           1       0.64      0.53      0.58        40\n           2       0.95      0.92      0.94       206\n           3       0.81      0.60      0.69        57\n           4       0.85      0.78      0.81       396\n           5       0.81      0.64      0.72        61\n           6       0.86      0.78      0.82        63\n           7       0.92      0.96      0.94       657\n           8       0.95      0.88      0.91       145\n\n    accuracy                           0.88      2332\n   macro avg       0.85      0.78      0.81      2332\nweighted avg       0.88      0.88      0.88      2332\n\nTrain/Test split=75.0/25.0\n              precision    recall  f1-score   support\n\n           0       0.84      0.92      0.88       734\n           1       0.70      0.55      0.61        42\n           2       0.97      0.91      0.94       220\n           3       0.80      0.63      0.70        59\n           4       0.85      0.78      0.81       412\n           5       0.85      0.61      0.71        64\n           6       0.78      0.73      0.76        64\n           7       0.92      0.97      0.95       685\n           8       0.94      0.89      0.92       149\n\n    accuracy                           0.88      2429\n   macro avg       0.85      0.78      0.81      2429\nweighted avg       0.88      0.88      0.88      2429\n\nTrain/Test split=74.0/26.0\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       755\n           1       0.74      0.52      0.61        44\n           2       0.96      0.93      0.95       229\n           3       0.77      0.63      0.70        63\n           4       0.84      0.79      0.82       427\n           5       0.90      0.65      0.75        68\n           6       0.79      0.69      0.74        65\n           7       0.92      0.96      0.94       717\n           8       0.94      0.88      0.91       159\n\n    accuracy                           0.88      2527\n   macro avg       0.86      0.78      0.81      2527\nweighted avg       0.88      0.88      0.88      2527\n\nTrain/Test split=73.0/27.0\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       785\n           1       0.69      0.61      0.65        44\n           2       0.97      0.93      0.95       238\n           3       0.83      0.61      0.70        66\n           4       0.84      0.79      0.81       448\n           5       0.92      0.64      0.76        73\n           6       0.82      0.75      0.78        67\n           7       0.92      0.97      0.94       739\n           8       0.95      0.88      0.91       164\n\n    accuracy                           0.88      2624\n   macro avg       0.87      0.79      0.82      2624\nweighted avg       0.88      0.88      0.88      2624\n\nTrain/Test split=72.0/28.000000000000004\n              precision    recall  f1-score   support\n\n           0       0.85      0.90      0.87       809\n           1       0.68      0.59      0.63        46\n           2       0.95      0.92      0.93       243\n           3       0.85      0.59      0.70        69\n           4       0.82      0.79      0.81       471\n           5       0.87      0.61      0.71        76\n           6       0.78      0.74      0.76        68\n           7       0.92      0.96      0.94       772\n           8       0.96      0.89      0.92       167\n\n    accuracy                           0.87      2721\n   macro avg       0.85      0.78      0.81      2721\nweighted avg       0.87      0.87      0.87      2721\n\nTrain/Test split=71.0/28.999999999999996\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       835\n           1       0.59      0.52      0.55        46\n           2       0.96      0.93      0.94       255\n           3       0.84      0.60      0.70        72\n           4       0.84      0.79      0.82       492\n           5       0.86      0.61      0.71        79\n           6       0.78      0.75      0.77        68\n           7       0.92      0.95      0.94       797\n           8       0.94      0.89      0.91       174\n\n    accuracy                           0.88      2818\n   macro avg       0.84      0.77      0.80      2818\nweighted avg       0.88      0.88      0.88      2818\n\nTrain/Test split=70.0/30.0\n              precision    recall  f1-score   support\n\n           0       0.84      0.91      0.87       856\n           1       0.62      0.57      0.60        49\n           2       0.96      0.92      0.94       268\n           3       0.81      0.62      0.70        74\n           4       0.81      0.78      0.80       510\n           5       0.92      0.59      0.72        82\n           6       0.79      0.72      0.76        69\n           7       0.93      0.96      0.95       823\n           8       0.95      0.88      0.91       184\n\n    accuracy                           0.87      2915\n   macro avg       0.85      0.77      0.80      2915\nweighted avg       0.87      0.87      0.87      2915\n\nTrain/Test split=69.0/31.0\n              precision    recall  f1-score   support\n\n           0       0.85      0.92      0.88       878\n           1       0.64      0.55      0.59        53\n           2       0.97      0.91      0.94       276\n           3       0.75      0.58      0.65        76\n           4       0.83      0.80      0.81       535\n           5       0.85      0.62      0.72        86\n           6       0.75      0.69      0.72        70\n           7       0.92      0.96      0.94       847\n           8       0.94      0.87      0.91       191\n\n    accuracy                           0.87      3012\n   macro avg       0.83      0.76      0.79      3012\nweighted avg       0.87      0.87      0.87      3012\n\nTrain/Test split=68.0/32.0\n              precision    recall  f1-score   support\n\n           0       0.83      0.90      0.87       906\n           1       0.67      0.57      0.62        56\n           2       0.97      0.91      0.94       293\n           3       0.74      0.61      0.67        76\n           4       0.81      0.77      0.79       544\n           5       0.86      0.62      0.72        88\n           6       0.81      0.71      0.76        79\n           7       0.93      0.96      0.94       873\n           8       0.93      0.88      0.91       195\n\n    accuracy                           0.87      3110\n   macro avg       0.84      0.77      0.80      3110\nweighted avg       0.87      0.87      0.87      3110\n\nTrain/Test split=67.0/33.0\n              precision    recall  f1-score   support\n\n           0       0.83      0.91      0.87       933\n           1       0.64      0.53      0.58        57\n           2       0.97      0.91      0.94       308\n           3       0.77      0.62      0.69        78\n           4       0.81      0.78      0.79       563\n           5       0.87      0.59      0.70        92\n           6       0.80      0.70      0.75        80\n           7       0.92      0.96      0.94       891\n           8       0.94      0.86      0.90       205\n\n    accuracy                           0.87      3207\n   macro avg       0.84      0.76      0.79      3207\nweighted avg       0.87      0.87      0.86      3207\n\nTrain/Test split=65.99999999999999/34.0\n              precision    recall  f1-score   support\n\n           0       0.83      0.90      0.86       955\n           1       0.67      0.56      0.61        59\n           2       0.95      0.91      0.93       318\n           3       0.78      0.62      0.69        81\n           4       0.81      0.78      0.80       584\n           5       0.89      0.59      0.71        94\n           6       0.79      0.70      0.74        83\n           7       0.92      0.96      0.94       919\n           8       0.95      0.87      0.91       211\n\n    accuracy                           0.87      3304\n   macro avg       0.84      0.76      0.80      3304\nweighted avg       0.87      0.87      0.87      3304\n\nTrain/Test split=65.0/35.0\n              precision    recall  f1-score   support\n\n           0       0.82      0.90      0.86       984\n           1       0.71      0.48      0.57        60\n           2       0.95      0.91      0.93       319\n           3       0.75      0.60      0.66        84\n           4       0.81      0.76      0.78       611\n           5       0.87      0.60      0.71        96\n           6       0.81      0.75      0.78        85\n           7       0.91      0.96      0.93       941\n           8       0.95      0.86      0.91       221\n\n    accuracy                           0.86      3401\n   macro avg       0.84      0.76      0.79      3401\nweighted avg       0.86      0.86      0.86      3401\n\n","output_type":"stream"}]}]}